/home/rstric2s/psi4conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Epoch [1/100], Loss: 51745.0859375
Epoch [2/100], Loss: 17031.603515625
Epoch [3/100], Loss: 14981.6015625
Epoch [4/100], Loss: 13319.7998046875
Epoch [5/100], Loss: 11935.3623046875
Epoch [6/100], Loss: 10765.759765625
Epoch [7/100], Loss: 9779.029296875
Epoch [8/100], Loss: 8954.560546875
Epoch [9/100], Loss: 8266.6875
Epoch [10/100], Loss: 7683.51123046875
Epoch [11/100], Loss: 7204.2939453125
Epoch [12/100], Loss: 6802.57470703125
Epoch [13/100], Loss: 6460.25830078125
Epoch [14/100], Loss: 6151.4072265625
Epoch [15/100], Loss: 5876.29296875
Epoch [16/100], Loss: 5649.24169921875
Epoch [17/100], Loss: 5440.5302734375
Epoch [18/100], Loss: 5256.931640625
Epoch [19/100], Loss: 5091.986328125
Epoch [20/100], Loss: 4951.7216796875
Epoch [21/100], Loss: 4823.22802734375
Epoch [22/100], Loss: 4707.07861328125
Epoch [23/100], Loss: 4606.63427734375
Epoch [24/100], Loss: 4517.7041015625
Epoch [25/100], Loss: 4439.833984375
Epoch [26/100], Loss: 4378.90283203125
Epoch [27/100], Loss: 4333.41455078125
Epoch [28/100], Loss: 4295.08056640625
Epoch [29/100], Loss: 4262.71728515625
Epoch [30/100], Loss: 4236.0361328125
Epoch [31/100], Loss: 4223.6591796875
Epoch [32/100], Loss: 4221.802734375
Epoch [33/100], Loss: 4228.28564453125
Epoch [34/100], Loss: 4241.2578125
Epoch [35/100], Loss: 4256.4794921875
Epoch [36/100], Loss: 4274.09814453125
Epoch [37/100], Loss: 4293.44091796875
Epoch [38/100], Loss: 4314.3984375
Epoch [39/100], Loss: 4329.2529296875
Epoch [40/100], Loss: 4339.91748046875
Epoch [41/100], Loss: 4344.4384765625
Epoch [42/100], Loss: 4346.69140625
Epoch [43/100], Loss: 4352.5927734375
Epoch [44/100], Loss: 4357.5791015625
Epoch [45/100], Loss: 4361.93994140625
Epoch [46/100], Loss: 4368.9970703125
Epoch [47/100], Loss: 4380.6962890625
Epoch [48/100], Loss: 4388.2861328125
Epoch [49/100], Loss: 4395.041015625
Epoch [50/100], Loss: 4397.857421875
Epoch [51/100], Loss: 4397.35595703125
Epoch [52/100], Loss: 4392.896484375
Epoch [53/100], Loss: 4383.484375
Epoch [54/100], Loss: 4371.7490234375
Epoch [55/100], Loss: 4354.42919921875
Epoch [56/100], Loss: 4333.470703125
Epoch [57/100], Loss: 4314.0859375
Epoch [58/100], Loss: 4296.1845703125
Epoch [59/100], Loss: 4285.66162109375
Epoch [60/100], Loss: 4271.24951171875
Epoch [61/100], Loss: 4251.0732421875
Epoch [62/100], Loss: 4227.22998046875
Epoch [63/100], Loss: 4199.09375
Epoch [64/100], Loss: 4167.638671875
Epoch [65/100], Loss: 4135.681640625
Epoch [66/100], Loss: 4100.2431640625
Epoch [67/100], Loss: 4063.18310546875
Epoch [68/100], Loss: 4021.591064453125
Epoch [69/100], Loss: 3977.856689453125
Epoch [70/100], Loss: 3933.205322265625
Epoch [71/100], Loss: 3885.19091796875
Epoch [72/100], Loss: 3834.9990234375
Epoch [73/100], Loss: 3782.9482421875
Epoch [74/100], Loss: 3730.5224609375
Epoch [75/100], Loss: 3677.15966796875
Epoch [76/100], Loss: 3622.99072265625
Epoch [77/100], Loss: 3567.92578125
Epoch [78/100], Loss: 3510.692626953125
Epoch [79/100], Loss: 3454.43896484375
Epoch [80/100], Loss: 3396.91748046875
Epoch [81/100], Loss: 3336.4443359375
Epoch [82/100], Loss: 3274.243896484375
Epoch [83/100], Loss: 3213.791015625
Epoch [84/100], Loss: 3152.304443359375
Epoch [85/100], Loss: 3088.12744140625
Epoch [86/100], Loss: 3025.503662109375
Epoch [87/100], Loss: 2963.986328125
Epoch [88/100], Loss: 2902.3447265625
Epoch [89/100], Loss: 2839.210205078125
Epoch [90/100], Loss: 2776.030517578125
Epoch [91/100], Loss: 2710.96142578125
Epoch [92/100], Loss: 2647.76953125
Epoch [93/100], Loss: 2581.798583984375
Epoch [94/100], Loss: 2514.95751953125
Epoch [95/100], Loss: 2448.346923828125
Epoch [96/100], Loss: 2379.8544921875
Epoch [97/100], Loss: 2311.60009765625
Epoch [98/100], Loss: 2241.505859375
Epoch [99/100], Loss: 2173.105224609375
Epoch [100/100], Loss: 2104.459716796875
