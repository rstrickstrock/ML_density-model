{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e370b49-b2d4-439f-a6eb-a4a088696e55",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd9ae87-7666-4ad7-96b0-acbd2f7ba3f8",
   "metadata": {},
   "source": [
    "## import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1206e9c5-f903-481e-a2d7-51afb38aa939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5ce80-42c8-4201-b13b-ed3ac73d2f49",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fbd23f7-9b0e-4ee9-9159-b7a0fbfb8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid sampling 1296\n",
    "data1296 = pd.read_csv('CLEANED_gridsearch_1296.csv')\n",
    "data1296 = data1296.drop(data1296.columns[0], axis=1)\n",
    "X_1296 = data1296.drop('density', axis=1)\n",
    "Y_1296 = data1296['density']\n",
    "#print(f'{data1296}')\n",
    "#print(f'{X_1296}')\n",
    "#print(f'{Y_1296}')\n",
    "\n",
    "## grid sampling 2401\n",
    "data2401 = pd.read_csv('CLEANED_gridsearch_2401.csv')\n",
    "data2401 = data2401.drop(data2401.columns[0], axis=1)\n",
    "X_2401 = data2401.drop('density', axis=1)\n",
    "Y_2401 = data2401['density']\n",
    "#print(f'{data2401}')\n",
    "#print(f'{X_2401}')\n",
    "#print(f'{Y_2401}')\n",
    "\n",
    "## sobol2 sampling\n",
    "data_sobol1 = pd.read_csv('CLEANED_sobolsampling-2048.csv')\n",
    "data_sobol1 = data_sobol1.drop(data_sobol1.columns[0], axis=1)\n",
    "X_sobol1 = data_sobol1.drop('density', axis=1)\n",
    "Y_sobol1 = data_sobol1['density']\n",
    "#print(f'{data_sobol1}')\n",
    "#print(f'{X_sobol1}')\n",
    "#print(f'{Y_sobol1}')\n",
    "\n",
    "## sobol2 sampling\n",
    "data_sobol2 = pd.read_csv('CLEANED_sobolsampling-2048-2.csv')\n",
    "data_sobol2 = data_sobol2.drop(data_sobol2.columns[0], axis=1)\n",
    "X_sobol2 = data_sobol2.drop('density', axis=1)\n",
    "Y_sobol2 = data_sobol2['density']\n",
    "#print(f'{data_sobol2}')\n",
    "#print(f'{X_sobol2}')\n",
    "#print(f'{Y_sobol2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062411db-5575-4420-bb04-dc14f14ea36a",
   "metadata": {},
   "source": [
    "## prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6c9c63-ff38-43f1-b317-38dc9a483f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## suggestions for random ints\n",
    "#random_array = np.random.rand(30)*100\n",
    "#random_array = random_array.astype(int)\n",
    "#print(f'{random_array}')\n",
    "\n",
    "## actually used random ints hard coded\n",
    "random_ints = [678, 147, 561, 237, 588, 951, 490, 395, 877, 297, 721, 711, 985, 171, 75, 16, 669, 530, 999, 794, 936, 111, 816, 968, 48, 986, 829, 996, 272, 759, 390, 930, 633, 928, 854, 554, 562, 78, 222, 294, 725, 582, 731, 249, 791, 35, 180, 510, 593, 634]\n",
    "#print(f'{np.sort(random_ints)}')\n",
    "trainingsizes = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6e3b7-507b-4383-92aa-fb317176a7a5",
   "metadata": {},
   "source": [
    "## split datasets\n",
    "create train/test sets based on random_ints and trainingsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275ccdb0-c6be-41d7-9ff3-5051bef24870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testsize = 0.95\n",
      "testsize = 0.9\n",
      "testsize = 0.85\n",
      "testsize = 0.8\n",
      "testsize = 0.75\n",
      "testsize = 0.7\n",
      "testsize = 0.65\n",
      "testsize = 0.6\n",
      "testsize = 0.55\n",
      "testsize = 0.5\n",
      "testsize = 0.45\n",
      "testsize = 0.4\n",
      "testsize = 0.35\n",
      "testsize = 0.3\n",
      "testsize = 0.25\n",
      "testsize = 0.2\n",
      "testsize = 0.15\n",
      "testsize = 0.1\n",
      "testsize = 0.05\n"
     ]
    }
   ],
   "source": [
    "## grid sampling 1296\n",
    "X_TRAINs1296 = []\n",
    "X_TESTs1296 = []\n",
    "Y_TRAINs1296 = []\n",
    "Y_TESTs1296 = []\n",
    "\n",
    "## grid sampling 2401\n",
    "X_TRAINs2401 = []\n",
    "X_TESTs2401 = []\n",
    "Y_TRAINs2401 = []\n",
    "Y_TESTs2401 = []\n",
    "\n",
    "## sobol sampling 1\n",
    "X_TRAINsSobol1 = []\n",
    "X_TESTsSobol1 = []\n",
    "Y_TRAINsSobol1 = []\n",
    "Y_TESTsSobol1 = []\n",
    "\n",
    "## sobol sampling 2\n",
    "X_TRAINsSobol2 = []\n",
    "X_TESTsSobol2 = []\n",
    "Y_TRAINsSobol2 = []\n",
    "Y_TESTsSobol2 = []\n",
    "\n",
    "for t in trainingsizes:\n",
    "    testsize = np.round(1.0 - np.round(float(t), 2), 2)\n",
    "    print(f'testsize = {testsize}')\n",
    "    ## grid sampling 1296\n",
    "    qX_TRAINs1296 = []\n",
    "    qX_TESTs1296 = []\n",
    "    qY_TRAINs1296 = []\n",
    "    qY_TESTs1296 = []\n",
    "    \n",
    "    ## grid sampling 2401\n",
    "    qX_TRAINs2401 = []\n",
    "    qX_TESTs2401 = []\n",
    "    qY_TRAINs2401 = []\n",
    "    qY_TESTs2401 = []\n",
    "    \n",
    "    ## sobol sampling 1\n",
    "    qX_TRAINsSobol1 = []\n",
    "    qX_TESTsSobol1 = []\n",
    "    qY_TRAINsSobol1 = []\n",
    "    qY_TESTsSobol1 = []\n",
    "    \n",
    "    ## sobol sampling 2\n",
    "    qX_TRAINsSobol2 = []\n",
    "    qX_TESTsSobol2 = []\n",
    "    qY_TRAINsSobol2 = []\n",
    "    qY_TESTsSobol2 = []\n",
    "\n",
    "    \n",
    "    for i in random_ints:\n",
    "        #print(f'{i}')\n",
    "        ## use the X_test, Y_test data for testing combined with all the data of the other datasets\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_1296, Y_1296, test_size=testsize, random_state=i)\n",
    "        qX_TRAINs1296.append(X_train)\n",
    "        qY_TRAINs1296.append(Y_train)\n",
    "        #print(f'{X_test}')\n",
    "        #print(f'{Y_test}')\n",
    "        X_test = pd.concat([X_test, X_2401, X_sobol1, X_sobol2], ignore_index=True)\n",
    "        Y_test = pd.concat([Y_test, Y_2401, Y_sobol1, Y_sobol2], ignore_index=True)\n",
    "        qX_TESTs1296.append(X_test)\n",
    "        qY_TESTs1296.append(Y_test)\n",
    "        #print(f'{X_test}')\n",
    "        #print(f'{Y_test}')\n",
    "        \n",
    "            \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_2401, Y_2401, test_size=testsize, random_state=i)\n",
    "        qX_TRAINs2401.append(X_train),\n",
    "        qY_TRAINs2401.append(Y_train)\n",
    "        X_test = pd.concat([X_test, X_1296, X_sobol1, X_sobol2], ignore_index=True)\n",
    "        Y_test = pd.concat([Y_test, Y_1296, Y_sobol1, Y_sobol2], ignore_index=True)\n",
    "        qX_TESTs2401.append(X_test)\n",
    "        qY_TESTs2401.append(Y_test)\n",
    "        \n",
    "            \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_sobol1, Y_sobol1, test_size=testsize, random_state=i)\n",
    "        qX_TRAINsSobol1.append(X_train)\n",
    "        qY_TRAINsSobol1.append(Y_train)\n",
    "        X_test = pd.concat([X_test, X_1296, X_2401, X_sobol2], ignore_index=True)\n",
    "        Y_test = pd.concat([Y_test, Y_1296, Y_2401, Y_sobol2], ignore_index=True)\n",
    "        qX_TESTsSobol1.append(X_test)\n",
    "        qY_TESTsSobol1.append(Y_test)\n",
    "        \n",
    "            \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_sobol2, Y_sobol2, test_size=testsize, random_state=i)\n",
    "        qX_TRAINsSobol2.append(X_train)\n",
    "        qY_TRAINsSobol2.append(Y_train)\n",
    "        X_test = pd.concat([X_test, X_1296, X_2401, X_sobol1], ignore_index=True)\n",
    "        Y_test = pd.concat([Y_test, Y_1296, Y_2401, Y_sobol1], ignore_index=True)\n",
    "        qX_TESTsSobol2.append(X_test)\n",
    "        qY_TESTsSobol2.append(Y_test)\n",
    "\n",
    "    ## grid sampling 1296\n",
    "    X_TRAINs1296.append(qX_TRAINs1296)\n",
    "    X_TESTs1296.append(qX_TESTs1296)\n",
    "    Y_TRAINs1296.append(qY_TRAINs1296)\n",
    "    Y_TESTs1296.append(qY_TESTs1296)\n",
    "    \n",
    "    ## grid sampling 2401\n",
    "    X_TRAINs2401.append(qX_TRAINs2401)\n",
    "    X_TESTs2401.append(qX_TESTs2401)\n",
    "    Y_TRAINs2401.append(qY_TRAINs2401)\n",
    "    Y_TESTs2401.append(qY_TESTs2401)\n",
    "    \n",
    "    ## sobol sampling 1\n",
    "    X_TRAINsSobol1.append(qX_TRAINsSobol1)\n",
    "    X_TESTsSobol1.append(qX_TESTsSobol1)\n",
    "    Y_TRAINsSobol1.append(qY_TRAINsSobol1)\n",
    "    Y_TESTsSobol1.append(qY_TESTsSobol1)\n",
    "    \n",
    "    ## sobol sampling 2\n",
    "    X_TRAINsSobol2.append(qX_TRAINsSobol2)\n",
    "    X_TESTsSobol2.append(qX_TESTsSobol2)\n",
    "    Y_TRAINsSobol2.append(qY_TRAINsSobol2)\n",
    "    Y_TESTsSobol2.append(qY_TESTsSobol2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f60530-1ade-4774-9a32-dc9ffd9c46c9",
   "metadata": {},
   "source": [
    "## create and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32a3c8f-1ff0-4584-bb7e-d58df3500cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 0.05% of the Data for training and 0.95% for testing ...\n",
      "\t1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\H-BRS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m         modelSobol1\u001b[38;5;241m.\u001b[39mfit(X_TRAINsSobol1[k][i], Y_TRAINsSobol1[k][i])\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m#        qMODELsSobol1.append(modelSobol1)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m         \u001b[43mmodelSobol2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_TRAINsSobol2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_TRAINsSobol2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m#        qMODELsSobol2.append(modelSobol2)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m         \n\u001b[0;32m     94\u001b[0m         \u001b[38;5;66;03m## prediction using the test set\u001b[39;00m\n\u001b[0;32m     95\u001b[0m         Y_prediction1296_mean, Y_prediction1296_std \u001b[38;5;241m=\u001b[39m model1296\u001b[38;5;241m.\u001b[39mpredict(X_TESTs1296[k][i], return_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:326\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer):\n\u001b[0;32m    324\u001b[0m         theta_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39muniform(bounds[:, \u001b[38;5;241m0\u001b[39m], bounds[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    325\u001b[0m         optima\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 326\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m         )\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[0;32m    330\u001b[0m lml_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m1\u001b[39m), optima))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:653\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 653\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[0;32m    661\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    728\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    729\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 731\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    734\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    735\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:343\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 294\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:298\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 298\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:577\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    574\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 577\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    579\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:963\u001b[0m, in \u001b[0;36mProduct.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m    962\u001b[0m     K1, K1_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 963\u001b[0m     K2, K2_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K1 \u001b[38;5;241m*\u001b[39m K2, np\u001b[38;5;241m.\u001b[39mdstack(\n\u001b[0;32m    965\u001b[0m         (K1_gradient \u001b[38;5;241m*\u001b[39m K2[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis], K2_gradient \u001b[38;5;241m*\u001b[39m K1[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis])\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:1558\u001b[0m, in \u001b[0;36mRBF.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1556\u001b[0m length_scale \u001b[38;5;241m=\u001b[39m _check_length_scale(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_scale)\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1558\u001b[0m     dists \u001b[38;5;241m=\u001b[39m \u001b[43mpdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlength_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msqeuclidean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m     K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m dists)\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;66;03m# convert from upper-triangular matrix to square matrix\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\spatial\\distance.py:2180\u001b[0m, in \u001b[0;36mpdist\u001b[1;34m(X, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2179\u001b[0m     pdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mpdist_func\n\u001b[1;32m-> 2180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2182\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## grid sampling 1296\n",
    "MODELs1296 = []\n",
    "Y_PREDICTIONs1296_MEAN = []\n",
    "Y_PREDICTIONs1296_STD = []\n",
    "RMSEs1296 = []\n",
    "R2s1296 = []\n",
    "SPEARMANRs1296 = []\n",
    "\n",
    "## grid sampling 2401\n",
    "MODELs2401 = []\n",
    "Y_PREDICTIONs2401_MEAN = []\n",
    "Y_PREDICTIONs2401_STD = []\n",
    "RMSEs2401 = []\n",
    "R2s2401 = []\n",
    "SPEARMANRs2401 = []\n",
    "\n",
    "## sobol sampling 1\n",
    "MODELsSobol1 = []\n",
    "Y_PREDICTIONsSobol1_MEAN = []\n",
    "Y_PREDICTIONsSobol1_STD = []\n",
    "RMSEsSobol1 = []\n",
    "R2sSobol1 = []\n",
    "SPEARMANRsSobol1 = []\n",
    "\n",
    "## sobol sampling 2\n",
    "MODELsSobol2 = []\n",
    "Y_PREDICTIONsSobol2_MEAN = []\n",
    "Y_PREDICTIONsSobol2_STD = []\n",
    "RMSEsSobol2 = []\n",
    "R2sSobol2 = []\n",
    "SPEARMANRsSobol2 = []\n",
    "\n",
    "kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "n_restarts = 9\n",
    "\n",
    "for k in range(0, len(trainingsizes)):\n",
    "    print(f'Training model with {trainingsizes[k]}% of the Data for training and {1-trainingsizes[k]}% for testing ...')\n",
    "    ## grid sampling 1296\n",
    "    qMODELs1296 = []\n",
    "    qY_PREDICTIONs1296_mean = []\n",
    "    qY_PREDICTIONs1296_std = []\n",
    "    qRMSEs1296 = []\n",
    "    qR2s1296 = []\n",
    "    qSPEARMANRs1296 = []\n",
    "    \n",
    "    ## grid sampling 2401\n",
    "    qMODELs2401 = []\n",
    "    qY_PREDICTIONs2401_mean = []\n",
    "    qY_PREDICTIONs2401_std = []\n",
    "    qRMSEs2401 = []\n",
    "    qR2s2401 = []\n",
    "    qSPEARMANRs2401 = []\n",
    "    \n",
    "    ## sobol sampling 1\n",
    "    qMODELsSobol1 = []\n",
    "    qY_PREDICTIONsSobol1_mean = []\n",
    "    qY_PREDICTIONsSobol1_std = []\n",
    "    qRMSEsSobol1 = []\n",
    "    qR2sSobol1 = []\n",
    "    qSPEARMANRsSobol1 = []\n",
    "    \n",
    "    ## sobol sampling 2\n",
    "    qMODELsSobol2 = []\n",
    "    qY_PREDICTIONsSobol2_mean = []\n",
    "    qY_PREDICTIONsSobol2_std = []\n",
    "    qRMSEsSobol2 = []\n",
    "    qR2sSobol2 = []\n",
    "    qSPEARMANRsSobol2 = []\n",
    "    \n",
    "    for i in range(0, len(random_ints)):\n",
    "        print(f'\\t{i+1}/{len(random_ints)}')\n",
    "        ## create the model\n",
    "        model1296 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=n_restarts, random_state=random_ints[i])\n",
    "        #\n",
    "        model2401 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=n_restarts, random_state=random_ints[i])\n",
    "        #\n",
    "        modelSobol1 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=n_restarts, random_state=random_ints[i])\n",
    "        #\n",
    "        modelSobol2 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=n_restarts, random_state=random_ints[i])\n",
    "        \n",
    "        ## train/fit the model\n",
    "        model1296.fit(X_TRAINs1296[k][i], Y_TRAINs1296[k][i])\n",
    "#        qMODELs1296.append(model1296)\n",
    "        #\n",
    "        model2401.fit(X_TRAINs2401[k][i], Y_TRAINs2401[k][i])\n",
    "#        qMODELs2401.append(model2401)\n",
    "        #\n",
    "        modelSobol1.fit(X_TRAINsSobol1[k][i], Y_TRAINsSobol1[k][i])\n",
    "#        qMODELsSobol1.append(modelSobol1)\n",
    "        #\n",
    "        modelSobol2.fit(X_TRAINsSobol2[k][i], Y_TRAINsSobol2[k][i])\n",
    "#        qMODELsSobol2.append(modelSobol2)\n",
    "        \n",
    "        ## prediction using the test set\n",
    "        Y_prediction1296_mean, Y_prediction1296_std = model1296.predict(X_TESTs1296[k][i], return_std=True)\n",
    "        qY_PREDICTIONs1296_mean.append(Y_prediction1296_mean)\n",
    "        qY_PREDICTIONs1296_std.append(Y_prediction1296_std)\n",
    "        #\n",
    "        Y_prediction2401_mean, Y_prediction2401_std = model2401.predict(X_TESTs2401[k][i], return_std=True)\n",
    "        qY_PREDICTIONs2401_mean.append(Y_prediction2401_mean)\n",
    "        qY_PREDICTIONs2401_std.append(Y_prediction2401_std)\n",
    "        #\n",
    "        Y_predictionSobol1_mean, Y_predictionSobol1_std = modelSobol1.predict(X_TESTsSobol1[k][i], return_std=True)\n",
    "        qY_PREDICTIONsSobol1_mean.append(Y_predictionSobol1_mean)\n",
    "        qY_PREDICTIONsSobol1_std.append(Y_predictionSobol1_std)\n",
    "        #\n",
    "        Y_predictionSobol2_mean, Y_predictionSobol2_std = modelSobol2.predict(X_TESTsSobol2[k][i], return_std=True)\n",
    "        qY_PREDICTIONsSobol2_mean.append(Y_predictionSobol2_mean)\n",
    "        qY_PREDICTIONsSobol2_std.append(Y_predictionSobol2_std)\n",
    "        \n",
    "        ## evaluate with Y_test\n",
    "        rmse1296 = np.sqrt(mean_squared_error(Y_TESTs1296[k][i], Y_prediction1296_mean))\n",
    "        r21296 = r2_score(Y_TESTs1296[k][i], Y_prediction1296_mean)\n",
    "        spearman_r1296 = stats.spearmanr(Y_TESTs1296[k][i], Y_prediction1296_mean)\n",
    "        qRMSEs1296.append(rmse1296)\n",
    "        qR2s1296.append(r21296)\n",
    "        qSPEARMANRs1296.append(spearman_r1296.statistic)\n",
    "        #\n",
    "        rmse2401 = np.sqrt(mean_squared_error(Y_TESTs2401[k][i], Y_prediction2401_mean))\n",
    "        r22401 = r2_score(Y_TESTs2401[k][i], Y_prediction2401_mean)\n",
    "        spearman_r2401 = stats.spearmanr(Y_TESTs2401[k][i], Y_prediction2401_mean)\n",
    "        qRMSEs2401.append(rmse2401)\n",
    "        qR2s2401.append(r22401)\n",
    "        qSPEARMANRs2401.append(spearman_r2401.statistic)\n",
    "        #\n",
    "        rmseSobol1 = np.sqrt(mean_squared_error(Y_TESTsSobol1[k][i], Y_predictionSobol1_mean))\n",
    "        r2Sobol1 = r2_score(Y_TESTsSobol1[k][i], Y_predictionSobol1_mean)\n",
    "        spearman_rSobol1 = stats.spearmanr(Y_TESTsSobol1[k][i], Y_predictionSobol1_mean)\n",
    "        qRMSEsSobol1.append(rmseSobol1)\n",
    "        qR2sSobol1.append(r2Sobol1)\n",
    "        qSPEARMANRsSobol1.append(spearman_rSobol1.statistic)\n",
    "        #\n",
    "        rmseSobol2 = np.sqrt(mean_squared_error(Y_TESTsSobol2[k][i], Y_predictionSobol2_mean))\n",
    "        r2Sobol2 = r2_score(Y_TESTsSobol2[k][i], Y_predictionSobol2_mean)\n",
    "        spearman_rSobol2 = stats.spearmanr(Y_TESTsSobol2[k][i], Y_predictionSobol2_mean)\n",
    "        qRMSEsSobol2.append(rmseSobol2)\n",
    "        qR2sSobol2.append(r2Sobol2)\n",
    "        qSPEARMANRsSobol2.append(spearman_rSobol2.statistic)\n",
    "\n",
    "    ## grid sampling 1296\n",
    "#    MODELs1296.append(qMODELs1296)\n",
    "    Y_PREDICTIONs1296_MEAN.append(qY_PREDICTIONs1296_mean)\n",
    "    Y_PREDICTIONs1296_STD.append(qY_PREDICTIONs1296_std)\n",
    "    RMSEs1296.append(qRMSEs1296)\n",
    "    R2s1296.append(qR2s1296)\n",
    "    SPEARMANRs1296.append(qSPEARMANRs1296)\n",
    "    \n",
    "    ## grid sampling 2401\n",
    "#    MODELs2401.append(qMODELs2401)\n",
    "    Y_PREDICTIONs2401_MEAN.append(qY_PREDICTIONs2401_mean)\n",
    "    Y_PREDICTIONs2401_STD.append(qY_PREDICTIONs2401_std)\n",
    "    RMSEs2401.append(qRMSEs2401)\n",
    "    R2s2401.append(qR2s2401)\n",
    "    SPEARMANRs2401.append(qSPEARMANRs2401)\n",
    "    \n",
    "    ## sobol sampling 1\n",
    "#    MODELsSobol1.append(qMODELsSobol1)\n",
    "    Y_PREDICTIONsSobol1_MEAN.append(qY_PREDICTIONsSobol1_mean)\n",
    "    Y_PREDICTIONsSobol1_STD.append(qY_PREDICTIONsSobol1_std)\n",
    "    RMSEsSobol1.append(qRMSEsSobol1)\n",
    "    R2sSobol1.append(qR2sSobol1)\n",
    "    SPEARMANRsSobol1.append(qSPEARMANRsSobol1)\n",
    "    \n",
    "    ## sobol sampling 2\n",
    "#    MODELsSobol2.append(qMODELsSobol2)\n",
    "    Y_PREDICTIONsSobol2_MEAN.append(qY_PREDICTIONsSobol2_mean)\n",
    "    Y_PREDICTIONsSobol2_STD.append(qY_PREDICTIONsSobol2_std)\n",
    "    RMSEsSobol2.append(qRMSEsSobol2)\n",
    "    R2sSobol2.append(qR2sSobol2)\n",
    "    SPEARMANRsSobol2.append(qSPEARMANRsSobol2)\n",
    "\n",
    "print(f'done.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd2e1d-d91f-4bd9-a393-594dda1bfc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
